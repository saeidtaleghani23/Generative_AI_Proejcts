# 🎨 CycleGAN for Image-to-Image Translation

This repository contains an implementation of **CycleGAN**, an unpaired image-to-image translation model. The model learns to translate images between two domains **without requiring paired training data**.

## 📌 Project Overview
- **Model Type:** CycleGAN (Generative Adversarial Network)
- **Number of Generators:** 2 (Generator A & Generator B)
- **Number of Discriminators:** 2 (Discriminator A & Discriminator B)
- **Key Concept:** **Cycle Consistency Loss** ensures that translations preserve the original content.

---

## 🖼️ How CycleGAN Works

| Domain | Generator | Discriminator |
|--------|-----------|--------------|
| **Domain 1 → Domain 2** | **Generator A** converts images from **Domain 1 to Domain 2**. | **Discriminator A** classifies real vs. fake images from Domain 2. |
| **Domain 2 → Domain 1** | **Generator B** converts images from **Domain 2 to Domain 1**. | **Discriminator B** classifies real vs. fake images from Domain 1. |

### 🔄 Cycle Consistency Training  
- **Forward Cycle:**  
  **Domain1 → Generator A → Domain2 → Generator B → Domain1**  
- **Backward Cycle:**  
  **Domain2 → Generator B → Domain1 → Generator A → Domain2**


---

## 🛠 Installation Guide

To replicate this project, set up the environment using Conda.

### **1️⃣ Clone the Repository**
```bash
git clone https://github.com/saeidtaleghani23/CycleGAN.git
cd CycleGAN
```

### 2️⃣ Create & Activate Conda Environment
```bash
conda env create -f env/env.yml
conda activate cyclegan
```

### 3️⃣ Verify Installation
Check installed package versions:
```bash
python -c "import tensorflow as tf; import numpy as np; import matplotlib; print(tf.__version__, np.__version__, matplotlib.__version__)"

```

## 📊 Dataset Information

The model is trained on the **[CycleGAN Dataset](http://efrosgans.eecs.berkeley.edu/cyclegan/datasets/)**.  
Available dataset options include:  

- **`apple2orange`** 🍏 → 🍊  
- **`summer2winter_yosemite`** ☀️ → ❄️  
- **`horse2zebra`** 🐴 → 🦓  
- **`vangogh2photo`** 🎨 → 📷 (default)  

### **📥 Download Dataset**
Modify `dataset_name` inside the code to select a different dataset:  

```python
dataset_name = 'vangogh2photo'  # Change this to any dataset you want
DOWNLOAD_URL = f'http://efrosgans.eecs.berkeley.edu/cyclegan/datasets/{dataset_name}.zip'
```

## 🚀 Running the Model  

All training and image generation steps are implemented in the Jupyter Notebook: [`CycleGAN.ipynb`](CycleGAN.ipynb).  

### **How to Run the Notebook**
Open the Jupyter Notebook:  
   ```bash
   jupyter notebook CycleGAN.ipynb
 ```

 Run all cells to train the CycleGAN and generate images.


## 🎭 Loss Functions Used  

CycleGAN optimizes a combination of **four loss functions**:  

| **Loss Type**                           | **Description** |
|-----------------------------------------|---------------|
| **Adversarial Loss** (L2-MSE)           | Ensures the generated images look real. |
| **Identity Loss** (L1-MAE)              | Helps preserve colors and style. |
| **Cycle Consistency Loss (Forward)** (L1-MAE)  | Ensures **Domain1 → Domain2 → Domain1** produces the original image. |
| **Cycle Consistency Loss (Backward)** (L1-MAE) | Ensures **Domain2 → Domain1 → Domain2** produces the original image. |


## 🎨 Results  

Below are some examples of images generated by CycleGAN during training:  

✅ The model improves image realism as training progresses.  

**Generated images at Epoch 61:**  
![Epoch 61](outputs_vangogh2photo/epoch61_batch_num0.png)  

**Generated images at Epoch 76:**  
![Epoch 76](outputs_vangogh2photo/epoch76_batch_num0.png)  

**Generated images at Epoch 90:**  
![Epoch 90](outputs_vangogh2photo/epoch90_batch_num200.png)  

---

## 📩 Contact  
👤 **Saeid Taleghani**  
📧 **Email:** [stalegha@uwaterloo.ca](mailto:stalegha@uwaterloo.ca)  
🔗 **GitHub:** [saeidtaleghani23](https://github.com/saeidtaleghani23)  
